data:
  source: "data/Nova.csv"
  claim_col: "claim"
  truth_col: "truth"
  # pair_ids: 0-indexed list, random-X, all
  pair_ids: "random-5"
  # for random sampling of pair_ids
  seed: 42 
agents:
  - name: literal
    role: "Literal Fact-Checker"
  - name: context
    role: "Context Guardian"
  - name: steelman
    role: "Steelman Advocate"
  - name: sceptic
    role: "Sceptic"

debate:
  max_rounds: 2

foreperson:
  rubric:
    - axis: numeric_fidelity
      question: "Are all numbers, units, and percentages in the claim supported by the truth?"
    - axis: scope_fidelity
      question: "Are who/where/when correctly represented?"
    - axis: causal_fidelity
      question: "Does the claim avoid causal leaps not supported by the truth?"
    - axis: certainty_fidelity
      question: "Are hedges and certainty preserved?"
    - axis: context_sufficiency
      question: "Are key caveats, qualifiers, or denominators reflected or not contradicted?"

models:
  parser: "gpt-4.1-mini"
  agents: "gpt-4.1-mini"
  debate_status: "gpt-4.1-mini"
  foreperson: "gpt-4.1-mini"

interactive: true  # show parse, votes, debate, verdict as they stream

# ElevenLabs TTS (optional). Set ELEVENLABS_API_KEY in .env
elevenlabs:
  enabled: false
  model_id: "eleven_multilingual_v2"
  max_chars_per_utterance: 2000
  voices:
    narrator: "EXAVITQu4vr4xnSDxMaL"   # Sarah - presents claim, truth, facts
    literal: "pNInz6obpgDQGcFmaJgB"    # Adam
    context: "TxGEqnHWrfWFTfGW9XjX"    # Josh
    steelman: "ErXwobaYiN019PkySvjV"   # Antoni
    sceptic: "GBv7mTt0atIp3Br8iCZE"    # Thomas
    foreperson: "IKne3meq5aSn9XLyUdCD" # Charlie